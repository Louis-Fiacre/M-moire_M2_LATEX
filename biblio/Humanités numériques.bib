
@article{garrette_ponctuation_2007,
	title = {De la ponctuation à l'analyse de la phrase : stylométrie comparée des Iphigénie de Rotrou et de Racine},
	volume = {63},
	issn = {0992-5279},
	url = {https://www.cairn.info/revue-litteratures-classiques1-2007-2-page-129.htm},
	doi = {10.3917/licla.063.0129},
	shorttitle = {De la ponctuation à l'analyse de la phrase},
	pages = {129--156},
	number = {2},
	journaltitle = {Littératures classiques},
	shortjournal = {Littératures classiques},
	author = {Garrette, Robert},
	urldate = {2023-04-18},
	date = {2007},
	langid = {french},
	note = {Place: Paris
Publisher: Armand Colin},
	keywords = {{HN}},
	file = {Snapshot:/home/lf/Zotero/storage/H7RWNLKF/revue-litteratures-classiques1-2007-2-page-129.html:text/html},
}

@online{noauthor_4lex4scantailor-advanced_nodate,
	title = {4lex4/scantailor-advanced: {ScanTailor} Advanced is the version that merges the features of the {ScanTailor} Featured and {ScanTailor} Enhanced versions, brings new ones and fixes.},
	url = {https://github.com/4lex4/scantailor-advanced},
	urldate = {2023-08-14},
	keywords = {{HN}},
	file = {4lex4/scantailor-advanced\: ScanTailor Advanced is the version that merges the features of the ScanTailor Featured and ScanTailor Enhanced versions, brings new ones and fixes.:/home/lf/Zotero/storage/YQM3VRBU/scantailor-advanced.html:text/html},
}

@online{noauthor_tesseract-ocrtesseract_nodate,
	title = {tesseract-ocr/tesseract: Tesseract Open Source {OCR} Engine (main repository)},
	url = {https://github.com/tesseract-ocr/tesseract},
	abstract = {Tesseract Open Source {OCR} Engine (main repository) - tesseract-ocr/tesseract},
	titleaddon = {{GitHub}},
	urldate = {2023-08-14},
	langid = {american},
	keywords = {{HN}},
	file = {tesseract-ocr/tesseract\: Tesseract Open Source OCR Engine (main repository):/home/lf/Zotero/storage/A78UXGAT/tesseract.html:text/html},
}

@article{cortes_support-vector_1995,
	title = {Support-vector networks},
	volume = {20},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/10.1007/BF00994018},
	doi = {10.1007/BF00994018},
	abstract = {The support-vector network is a new leaming machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very highdimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.},
	pages = {273--297},
	number = {3},
	journaltitle = {Machine Learning},
	shortjournal = {Mach Learn},
	author = {Cortes, Corinna and Vapnik, Vladimir},
	urldate = {2023-08-14},
	date = {1995-09},
	langid = {english},
	keywords = {{HN}, {SVM}},
	file = {Cortes et Vapnik - 1995 - Support-vector networks.pdf:/home/lf/Zotero/storage/JFZMC2WK/Cortes et Vapnik - 1995 - Support-vector networks.pdf:application/pdf},
}

@article{pasmann_review_nodate,
	title = {Review John Burrows: Delta - A Measure of Stylistic Difference},
	author = {Paßmann, Robert},
	langid = {english},
	keywords = {{HN}},
	file = {Paßmann - John Burrows Delta - A Measure of Stylistic Diffe.pdf:/home/lf/Zotero/storage/G8Q9LQF6/Paßmann - John Burrows Delta - A Measure of Stylistic Diffe.pdf:application/pdf},
}

@article{evert_understanding_2017,
	title = {Understanding and explaining Delta measures for authorship attribution},
	volume = {32},
	issn = {2055-7671, 2055-768X},
	url = {http://academic.oup.com/dsh/article/32/suppl_2/ii4/3865676},
	doi = {10.1093/llc/fqx023},
	pages = {ii4--ii16},
	issue = {suppl\_2},
	journaltitle = {Digital Scholarship in the Humanities},
	author = {Evert, Stefan and Proisl, Thomas and Jannidis, Fotis and Reger, Isabella and Pielström, Steffen and Schöch, Christof and Vitt, Thorsten},
	urldate = {2023-08-14},
	date = {2017-12-01},
	langid = {english},
	keywords = {{HN}},
	file = {Evert et al. - 2017 - Understanding and explaining Delta measures for au.pdf:/home/lf/Zotero/storage/TGPVFPFH/Evert et al. - 2017 - Understanding and explaining Delta measures for au.pdf:application/pdf},
}

@article{benzecri_histoire_nodate,
	title = {Histoire et préhistoire de l'analyse des données. Partie I La préhistoire},
	author = {Benzécri, J P},
	langid = {french},
	keywords = {{HN}},
	file = {Benzécri - Histoire et préhistoire de l'analyse des données. .pdf:/home/lf/Zotero/storage/YZYKFE5M/Benzécri - Histoire et préhistoire de l'analyse des données. .pdf:application/pdf},
}

@inproceedings{karlgren_recognizing_1994,
	location = {Kyoto, Japan},
	title = {Recognizing text genres with simple metrics using discriminant analysis},
	volume = {2},
	url = {http://portal.acm.org/citation.cfm?doid=991250.991324},
	doi = {10.3115/991250.991324},
	abstract = {A simple method for categorizing texts into pre-determined text genre categories using the statistical standard technique of discriminant analysis is demonstrated with application to the Brown corpus. Discriminant analysis makes it possible use a large number of parameters that may be speciﬁc for a certain corpus or information stream, and combine them into a small number of functions, with the parameters weighted on basis of how useful they are for discriminating text genres. An application to information retrieval is discussed.},
	eventtitle = {the 15th conference},
	pages = {1071},
	booktitle = {Proceedings of the 15th conference on Computational linguistics  -},
	publisher = {Association for Computational Linguistics},
	author = {Karlgren, Jussi and Cutting, Douglass},
	urldate = {2023-08-14},
	date = {1994},
	langid = {english},
	keywords = {{HN}},
	file = {Karlgren et Cutting - 1994 - Recognizing text genres with simple metrics using .pdf:/home/lf/Zotero/storage/AG5DP6WJ/Karlgren et Cutting - 1994 - Recognizing text genres with simple metrics using .pdf:application/pdf},
}

@article{pincemin_apports_nodate,
	title = {Apports de la textométrie à l'analyse de corpus littéraires numériques},
	author = {Pincemin, Bénédicte and de Lyon, Université},
	langid = {french},
	keywords = {{HN}},
	file = {Pincemin et de Lyon - Apports de la textométrie à l'analyse de corpus li.pdf:/home/lf/Zotero/storage/3EZYXY8F/Pincemin et de Lyon - Apports de la textométrie à l'analyse de corpus li.pdf:application/pdf},
}

@article{legallois_reperer_2016,
	title = {Repérer les clichés dans les romans sentimentaux grâce à la méthode des « motifs »},
	issn = {1146-6480, 1960-6052},
	url = {http://journals.openedition.org/lidil/3950},
	doi = {10.4000/lidil.3950},
	abstract = {This paper deals with the exploration of genre-specific phraseology, more precisely, of “sequential patterns” expressing clichés. In our approach, a sequential pattern (or “motif”) is a specific and regular lexical and grammatical configuration. This unit is automatically detected; genre-specific motifs are calculated on the basis of two alternative methods (mutual information and calcul of specificities). The analysis is based on a large number of illustrations taken from a corpus of 150 contemporary novels: 50 “serious” novels, 50 crime novels and 50 sentimental novels. The study supports our initial hypothesis: sentimental novels are characterized by a high level of clichés, and these clichés are expressed through specific sequential patterns.},
	pages = {95--117},
	number = {53},
	journaltitle = {Lidil},
	shortjournal = {lidil},
	author = {Legallois, Dominique and Charnois, Thierry and Poibeau, Thierry},
	urldate = {2023-08-14},
	date = {2016-05-30},
	langid = {french},
	keywords = {{HN}},
	file = {Legallois et al. - 2016 - Repérer les clichés dans les romans sentimentaux g.pdf:/home/lf/Zotero/storage/6MZDCUJA/Legallois et al. - 2016 - Repérer les clichés dans les romans sentimentaux g.pdf:application/pdf},
}

@article{rinck_styles_2007,
	title = {Styles d’auteur et singularité des textes. Approche stylométrique du genre de l’article en linguistique},
	volume = {135},
	issn = {0338-2389},
	url = {https://www.persee.fr/doc/prati_0338-2389_2007_num_135_1_2160},
	doi = {10.3406/prati.2007.2160},
	abstract = {Fanny Rinck s’intéresse au genre de l’article de recherche en linguistique et aux styles au sens d’usages singuliers qu’un auteur fait du genre. Elle se base sur une approche stylométrique et sur les méthodes de la linguistique de corpus pour mettre en évidence les caractéristiques spécifiques des textes de 15 auteurs au niveau morpho-syntaxique et lexical. L’analyse montre que certaines s’assimilent à un usage idiomatique de la langue et du genre, aux plans syntaxique, énonciatif et argumentatif. D’autres sont liées aux concepts abordés dans les articles et au type d’études qui y sont présentés. En comparant en quoi le genre varie avec l’auteur et indépendamment de lui, on rend compte de la tension entre normes individuelles et collectives du genre et la singularité des textes en termes de profils qui structurent de manière relativement stable le genre et le champ considéré.},
	pages = {119--136},
	number = {1},
	journaltitle = {Pratiques},
	shortjournal = {prati},
	author = {Rinck, Fanny},
	urldate = {2023-08-14},
	date = {2007},
	langid = {french},
	keywords = {{HN}},
	file = {Rinck - 2007 - Styles d’auteur et singularité des textes. Approch.pdf:/home/lf/Zotero/storage/8W7Y3V3X/Rinck - 2007 - Styles d’auteur et singularité des textes. Approch.pdf:application/pdf},
}

@article{eder_stylometry_2016,
	title = {Stylometry with R: A Package for Computational Text Analysis},
	volume = {8},
	issn = {2073-4859},
	url = {https://journal.r-project.org/archive/2016/RJ-2016-007/index.html},
	doi = {10.32614/RJ-2016-007},
	shorttitle = {Stylometry with R},
	abstract = {This software paper describes ‘Stylometry with R’ (stylo), a ﬂexible R package for the highlevel analysis of writing style in stylometry. Stylometry (computational stylistics) is concerned with the quantitative study of writing style, e.g. authorship veriﬁcation, an application which has considerable potential in forensic contexts, as well as historical research. In this paper we introduce the possibilities of stylo for computational text analysis, via a number of dummy case studies from English and French literature. We demonstrate how the package is particularly useful in the exploratory statistical analysis of texts, e.g. with respect to authorial writing style. Because stylo provides an attractive graphical user interface for high-level exploratory analyses, it is especially suited for an audience of novices, without programming skills (e.g. from the Digital Humanities). More experienced users can beneﬁt from our implementation of a series of standard pipelines for text processing, as well as a number of similarity metrics.},
	pages = {107},
	number = {1},
	journaltitle = {The R Journal},
	shortjournal = {The R Journal},
	author = {Eder, Maciej and Rybicki, Jan and Kestemont, Mike},
	urldate = {2023-08-14},
	date = {2016},
	langid = {english},
	keywords = {{HN}},
	file = {Eder et al. - 2016 - Stylometry with R A Package for Computational Tex.pdf:/home/lf/Zotero/storage/9RIICBN2/Eder et al. - 2016 - Stylometry with R A Package for Computational Tex.pdf:application/pdf},
}

@online{noauthor_morphosyntaxe_nodate,
	title = {Morphosyntaxe et étude des genres - le roman policier},
	url = {http://www.revue-texto.net/Inedits/Beauvisage/Etude-polar_I-B.html},
	urldate = {2023-08-14},
	keywords = {{HN}},
	file = {Morphosyntaxe et étude des genres - le roman policier:/home/lf/Zotero/storage/U7NHDC45/Etude-polar_I-B.html:text/html},
}

@online{beauvisage_exploiter_nodate,
	title = {Exploiter des données morphosyntaxiques pour l'étude statistique des genres - Application au roman policier. Texto !},
	url = {http://www.revue-texto.net/Inedits/Beauvisage/index.html},
	titleaddon = {http://www.revue-texto.net/Inedits/Beauvisage/index.html},
	author = {{BEAUVISAGE}, Thomas},
	urldate = {2023-08-14},
	langid = {french},
	keywords = {{HN}, morphosyntaxe},
	file = {Beauvisage \: Exploiter des données morphosyntaxiques pour l'étude statistique des genres:/home/lf/Zotero/storage/7BL53GE8/index.html:text/html},
}

@article{cleuziou_classification_2008,
	title = {Classification de textes en domaines et en genres en combinant morphosyntaxe et lexique},
	abstract = {Nous présentons dans cet article le bilan de notre participation au 4e {DÉfi} Fouille de Textes 2008. L'étude porte sur la problématique de la classification textuelle en domaines et en genres qui représente un enjeu pour la Recherche d’Information ({RI}). Sa mise en œuvre nécessite notamment la sélection d’un ensemble de descripteurs adéquats. On considère généralement que les domaines sont corrélés au niveau du contenu (mots, termes, etc.) tandis que les genres sont discriminés au niveau morphosyntaxique. Malgré les bons résultats obtenus par ces choix méthodologiques, peu de travaux ont cherché à mesurer l'impact et la complémentarité des deux niveaux de description pour la classification. Le cadre pratique de ce défi permettra de compléter les premiers postulats formulés sur ce travail.},
	author = {Cleuziou, Guillaume and Poudat, Céline},
	date = {2008},
	keywords = {{HN}, morphosyntaxe},
	file = {CP_TALNDEFT_08.pdf:/home/lf/Zotero/storage/NP7TTSI3/CP_TALNDEFT_08.pdf:application/pdf},
}

@thesis{illouz_typage_2000,
	title = {Typage de données textuelles et adaptation des traitements linguistiques Application à l'annotation morpho-syntaxique},
	type = {phdthesis},
	author = {Illouz, Gabriel},
	date = {2000-01-01},
	keywords = {{HN}},
}

@article{poudat_categorisation_2006,
	title = {Catégorisation de textes en domaines et genres. Complémentarité des indexations lexicale et morphosyntaxique},
	volume = {9},
	url = {https://www.cairn.info/revue-document-numerique-2006-1-page-61.htm},
	doi = {10.3166/dn.9.1.61-76},
	shorttitle = {Catégorisation de textes en domaines et genres},
	abstract = {{RésuméCet} article traite du choix de descripteurs linguistiques appropriés pour caractériser et classifier les textes. On considère généralement que les domaines sont corrélés au niveau du contenu (mots, termes, etc.) tandis que les genres sont discriminés au niveau morphosyntaxique. Malgré les bons résultats obtenus par ces choix méthodologiques, peu de travaux ont cherché à mesurer l’impact et la complémentarité des deux niveaux de description pour la classification. Cette étude vise ainsi à évaluer l’intérêt discriminant des descripteurs morphosyntaxiques et thématiques pour classer les genres et les domaines. Des résultats encourageants sont obtenus sur un corpus pilote de textes scientifiques français.},
	pages = {61--76},
	number = {1},
	journaltitle = {Document numérique},
	shortjournal = {Document numérique},
	author = {Poudat, Céline and Cleuziou, Guillaume and Clavier, Viviane},
	date = {2006},
	note = {Place: Cachan
Publisher: Lavoisier},
	keywords = {{HN}},
	file = {Poudat et al. - 2006 - Catégorisation de textes en domaines et genres. Co.pdf:/home/lf/Zotero/storage/4Y4PNJRX/Poudat et al. - 2006 - Catégorisation de textes en domaines et genres. Co.pdf:application/pdf},
}

@article{philippe_traitement_2005,
	title = {Traitement stylistique et traitement idiolectal des singularités langagières},
	issn = {0765-4944, 2111-5044},
	url = {http://journals.openedition.org/praxematique/1659},
	doi = {10.4000/praxematique.1659},
	pages = {77--92},
	number = {44},
	journaltitle = {Cahiers de praxématique},
	shortjournal = {praxematique},
	author = {Philippe, Gilles},
	urldate = {2021-11-23},
	date = {2005-01-01},
	keywords = {{HN}},
}

@book{moretti_distant_2013,
	location = {London},
	title = {Distant reading},
	isbn = {978-1-78168-333-0},
	abstract = {How does a literary historian end up thinking in terms of z-scores, principal component analysis, and clustering coefficients' The essays in Distant Reading led to a new and often contested paradigm of literary analysis. In presenting them here Franco Moretti reconstructs his intellectual trajectory, the theoretical influences over his work, and explores the polemics that have often developed around his positions. From the evolutionary model of "Modern European Literature," through the geo-cultural insights of "Conjectures of World Literature" and "Planet Hollywood," to the quantitative findings of "Style, inc." and the abstract patterns of "Network Theory, Plot Analysis," the book follows two decades of conceptual development, organizing them around the metaphor of "distant reading," that has come to define'well beyond the wildest expectations of its author'a growing field of unorthodox literary studies},
	publisher = {Verso},
	author = {Moretti, Franco},
	date = {2013},
	keywords = {{HN}},
}

@article{van_cranenburgh_vector_2019,
	title = {Vector space explorations of literary language},
	volume = {53},
	issn = {1574-020X, 1574-0218},
	url = {http://link.springer.com/10.1007/s10579-018-09442-4},
	doi = {10.1007/s10579-018-09442-4},
	pages = {625--650},
	number = {4},
	journaltitle = {Language Resources and Evaluation},
	shortjournal = {Lang Resources \& Evaluation},
	author = {van Cranenburgh, Andreas and van Dalen-Oskam, Karina and van Zundert, Joris},
	urldate = {2021-11-01},
	date = {2019-12},
	keywords = {{HN}},
}

@inproceedings{van_cranenburgh_identifying_2015,
	title = {Identifying Literary Texts with Bigrams},
	url = {http://aclweb.org/anthology/W15-0707},
	doi = {10.3115/v1/W15-0707},
	abstract = {We study perceptions of literariness in a set of contemporary Dutch novels. Experiments with machine learning models show that it is possible to automatically distinguish novels that are seen as highly literary from those that are seen as less literary, using surprisingly simple textual features. The most discriminating features of our classiﬁcation model indicate that genre might be a confounding factor, but a regression model shows that we can also explain variation between highly literary novels from less literary ones within genre.},
	eventtitle = {Proceedings of the Fourth Workshop on Computational Linguistics for Literature},
	pages = {58--67},
	booktitle = {Proceedings of the Fourth Workshop on Computational Linguistics for Literature},
	publisher = {Association for Computational Linguistics},
	author = {van Cranenburgh, Andreas and Koolen, Corina},
	urldate = {2021-11-01},
	date = {2015},
	note = {Place: Denver, Colorado, {USA}},
	keywords = {{HN}},
}

@inproceedings{ribeiro_why_2016,
	title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
	isbn = {978-1-4503-4232-2},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939778},
	doi = {10.1145/2939672.2939778},
	shorttitle = {"Why Should I Trust You?},
	eventtitle = {{KDD} '16: The 22nd {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
	pages = {1135--1144},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
	publisher = {{ACM}},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	urldate = {2021-11-03},
	date = {2016-08-13},
	note = {Place: San Francisco California {USA}},
	keywords = {{HN}},
}

@article{burrows_ocean_1989,
	title = {An ocean where each kind..: Statistical analysis and some major determinants of literary style},
	volume = {23},
	issn = {0010-4817, 1572-8412},
	url = {http://link.springer.com/10.1007/BF02176636},
	doi = {10.1007/BF02176636},
	shorttitle = {‘An ocean where each kind. . .’},
	pages = {309--321},
	number = {4},
	journaltitle = {Computers and the Humanities},
	shortjournal = {Comput Hum},
	author = {Burrows, J. F.},
	urldate = {2021-11-09},
	date = {1989-08},
	keywords = {{HN}},
}

@article{wilson_harmonic_2019,
	title = {The harmonic mean p -value for combining dependent tests},
	volume = {116},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1814092116},
	doi = {10.1073/pnas.1814092116},
	abstract = {Analysis of “big data” frequently involves statistical comparison of millions of competing hypotheses to discover hidden processes underlying observed patterns of data, for example, in the search for genetic determinants of disease in genome-wide association studies ({GWAS}). Controlling the familywise error rate ({FWER}) is considered the strongest protection against false positives but makes it difficult to reach the multiple testing-corrected significance threshold. Here, I introduce the harmonic mean p -value ({HMP}), which controls the {FWER} while greatly improving statistical power by combining dependent tests using generalized central limit theorem. I show that the {HMP} effortlessly combines information to detect statistically significant signals among groups of individually nonsignificant hypotheses in examples of a human {GWAS} for neuroticism and a joint human–pathogen {GWAS} for hepatitis C viral load. The {HMP} simultaneously tests all ways to group hypotheses, allowing the smallest groups of hypotheses that retain significance to be sought. The power of the {HMP} to detect significant hypothesis groups is greater than the power of the Benjamini–Hochberg procedure to detect significant hypotheses, although the latter only controls the weaker false discovery rate ({FDR}). The {HMP} has broad implications for the analysis of large datasets, because it enhances the potential for scientific discovery.},
	pages = {1195--1200},
	number = {4},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {Proc Natl Acad Sci {USA}},
	author = {Wilson, Daniel J.},
	urldate = {2021-11-09},
	date = {2019-01-22},
	keywords = {{HN}},
}

@article{mironczuk_recent_2018,
	title = {A recent overview of the state-of-the-art elements of text classification},
	volume = {106},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S095741741830215X},
	doi = {10.1016/j.eswa.2018.03.058},
	pages = {36--54},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Mirończuk, Marcin Michał and Protasiewicz, Jarosław},
	urldate = {2021-11-09},
	date = {2018-09},
	keywords = {{HN}},
}

@inproceedings{lagutina_survey_2019,
	title = {A Survey on Stylometric Text Features},
	isbn = {978-952-69244-0-3},
	url = {https://ieeexplore.ieee.org/document/8981504/},
	doi = {10.23919/FRUCT48121.2019.8981504},
	eventtitle = {2019 25th Conference of Open Innovations Association ({FRUCT})},
	pages = {184--195},
	booktitle = {2019 25th Conference of Open Innovations Association ({FRUCT})},
	publisher = {{IEEE}},
	author = {Lagutina, Ksenia and Lagutina, Nadezhda and Boychuk, Elena and Vorontsova, Inna and Shliakhtina, Elena and Belyaeva, Olga and Paramonov, Ilya and Demidov, P.G.},
	urldate = {2021-11-09},
	date = {2019-11},
	note = {Place: Helsinki, Finland},
	keywords = {{HN}},
}

@article{burrows_delta_2002,
	title = {'Delta': a Measure of Stylistic Difference and a Guide to Likely Authorship},
	volume = {17},
	issn = {0268-1145, 1477-4615},
	url = {https://academic.oup.com/dsh/article-lookup/doi/10.1093/llc/17.3.267},
	doi = {10.1093/llc/17.3.267},
	shorttitle = {'Delta'},
	pages = {267--287},
	number = {3},
	journaltitle = {Literary and Linguistic Computing},
	shortjournal = {Literary and Linguistic Computing},
	author = {Burrows, John},
	urldate = {2021-11-15},
	date = {2002-09-01},
	keywords = {{HN}},
}

@article{long_literary_2016,
	title = {Literary Pattern Recognition: Modernism between Close Reading and Machine Learning},
	volume = {42},
	issn = {0093-1896, 1539-7858},
	url = {https://www.journals.uchicago.edu/doi/10.1086/684353},
	doi = {10.1086/684353},
	shorttitle = {Literary Pattern Recognition},
	pages = {235--267},
	number = {2},
	journaltitle = {Critical Inquiry},
	shortjournal = {Critical Inquiry},
	author = {Long, Hoyt and So, Richard Jean},
	urldate = {2021-11-23},
	date = {2016-01},
	keywords = {{HN}},
}

@article{bane_quantifying_nodate,
	title = {Quantifying and Measuring Morphological Complexity},
	pages = {9},
	author = {Bane, Max},
	keywords = {{HN}},
}

@article{yu_evaluation_2008,
	title = {An evaluation of text classification methods for literary study},
	volume = {23},
	issn = {0268-1145},
	url = {https://academic.oup.com/dsh/article-lookup/doi/10.1093/llc/fqn015},
	doi = {10.1093/llc/fqn015},
	pages = {327--343},
	number = {3},
	journaltitle = {Literary and Linguistic Computing},
	shortjournal = {Literary and Linguistic Computing},
	author = {Yu, B.},
	urldate = {2022-01-04},
	date = {2008-09-05},
	keywords = {{HN}},
	file = {Texte intégral:/home/lf/Zotero/storage/IS6NNRGX/Yu - 2008 - An evaluation of text classification methods for l.pdf:application/pdf},
}

@book{juola_six_2017,
	title = {Six Septembers: mathematics for the humanist},
	url = {http://digitalcommons.unl.edu/zeabook/55/},
	shorttitle = {Six Septembers},
	abstract = {Scholars of all stripes are turning their attention to materials that represent enormous opportunities for the future of humanistic inquiry. The purpose of this book is to impart the concepts that underlie the mathematics they are likely to encounter and to unfold the notation in a way that removes that particular barrier completely. This book is a primer for developing the skills to enable humanist scholars to address complicated technical material with confidence. This book, to put it plainly, is concerned with the things that the author of a technical article knows, but isn't saying. Like any field, mathematics operates under a regime of shared assumptions, and it is our purpose to elucidate some of those assumptions for the newcomer. The individual subjects we tackle are (in order): logic and proof, discrete mathematics, abstract algebra, probability and statistics, calculus, and differential equations.},
	author = {Juola, Patrick and Ramsay, Stephen},
	urldate = {2022-01-11},
	date = {2017},
	keywords = {{HN}},
}

@inproceedings{kestemont_function_2014,
	title = {Function Words in Authorship Attribution. From Black Magic to Theory?},
	url = {http://aclweb.org/anthology/W14-0908},
	doi = {10.3115/v1/W14-0908},
	eventtitle = {Proceedings of the 3rd Workshop on Computational Linguistics for Literature ({CLFL})},
	pages = {59--66},
	booktitle = {Proceedings of the 3rd Workshop on Computational Linguistics for Literature ({CLFL})},
	publisher = {Association for Computational Linguistics},
	author = {Kestemont, Mike},
	urldate = {2022-03-08},
	date = {2014},
	note = {Place: Gothenburg, Sweden},
	keywords = {{HN}},
}

@incollection{legallois_balance_2018,
	title = {The balance between quantitative and qualitative literary stylistics: how the method of “motifs” can help},
	isbn = {978-3-11-059586-4},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110595864-008/html},
	shorttitle = {The balance between quantitative and qualitative literary stylistics},
	pages = {164--193},
	booktitle = {The Grammar of Genres and Styles},
	publisher = {De Gruyter},
	author = {Legallois, Dominique and Charnois, Thierry and Larjavaara, Meri},
	editor = {Legallois, Dominique and Charnois, Thierry and Larjavaara, Meri},
	urldate = {2022-03-10},
	date = {2018-04-09},
	doi = {10.1515/9783110595864-008},
	keywords = {{HN}},
}

@article{cafiero_why_2019,
	title = {Why Molière most likely did write his plays},
	volume = {5},
	issn = {2375-2548},
	url = {https://www.science.org/doi/10.1126/sciadv.aax5489},
	doi = {10.1126/sciadv.aax5489},
	abstract = {Quantitative linguistics contradicts the much publicized theory naming Corneille as the author of Molière’s masterpieces. , As for Shakespeare, a hard-fought debate has emerged about Molière, a supposedly uneducated actor who, according to some, could not have written the masterpieces attributed to him. In the past decades, the century-old thesis according to which Pierre Corneille would be their actual author has become popular, mostly because of new works in computational linguistics. These results are reassessed here through state-of-the-art attribution methods. We study a corpus of comedies in verse by major authors of Molière and Corneille’s time. Analysis of lexicon, rhymes, word forms, affixes, morphosyntactic sequences, and function words do not give any clue that another author among the major playwrights of the time would have written the plays signed under the name Molière.},
	pages = {eaax5489},
	number = {11},
	journaltitle = {Science Advances},
	shortjournal = {Sci. Adv.},
	author = {Cafiero, Florian and Camps, Jean-Baptiste},
	urldate = {2022-04-17},
	date = {2019-11},
	keywords = {{HN}},
}

@article{moretti_operationalizing_2013,
	title = {“Operationalizing”: or, the function of measurement in modern literary theory},
	url = {https://litlab.stanford.edu/LiteraryLabPamphlet6.pdf.},
	series = {Pamphlets of the Stanford Literary Lab},
	number = {6},
	author = {Moretti, Franco},
	date = {2013},
	keywords = {{HN}},
}

@article{moretti_literature_2016,
	title = {Literature, Measured},
	url = {https://litlab.stanford.edu/LiteraryLabPamphlet12.pdf.},
	series = {Pamphlets of the Stanford Literary Lab},
	number = {12},
	author = {Moretti, Franco},
	date = {2016},
	keywords = {{HN}},
}

@article{moretti_style_2009,
	title = {Style, Inc. Reflections on Seven Thousand Titles (British Novels, 1740–1850)},
	volume = {36},
	issn = {00931896, 15397858},
	url = {http://www.jstor.org/stable/10.1086/606125},
	doi = {10.1086/606125},
	pages = {134--158},
	number = {1},
	journaltitle = {Critical Inquiry},
	author = {Moretti, Franco},
	urldate = {2022-04-28},
	date = {2009},
	note = {Publisher: The University of Chicago Press},
	keywords = {{HN}},
}

@online{kowalczyk_linear_2014,
	title = {Linear Kernel: Why is it recommended for text classification ?},
	url = {https://www.svm-tutorial.com/2014/10/svm-linear-kernel-good-text-classification/},
	shorttitle = {Linear Kernel},
	abstract = {A linear kernel is often recommended for text classification with {SVM} because text data has a lot of features and is often linearly separable.},
	titleaddon = {{SVM} Tutorial},
	author = {{KOWALCZYK}, Alexandre},
	urldate = {2023-08-17},
	date = {2014-10-19},
	langid = {american},
	keywords = {{HN}},
	file = {Snapshot:/home/lf/Zotero/storage/DBB8XRZZ/svm-linear-kernel-good-text-classification.html:text/html},
}

@software{camps_supervised_2021,
	title = {{SUPERvised} {STYLometry} ({SuperStyl})},
	rights = {{GPL}-3.0},
	url = {https://github.com/SupervisedStylometry/SuperStyl},
	abstract = {Supervised Stylometry},
	version = {0.9.0},
	author = {Camps, Jean-Baptiste},
	urldate = {2023-08-17},
	date = {2021-10},
	doi = {NONE},
	note = {original-date: 2021-02-26T13:38:37Z},
	keywords = {{HN}},
}

@inproceedings{gerard_genre_2008,
	location = {Paris, France},
	title = {Genre et variations stylistiques en sémantique textuelle},
	url = {http://www.linguistiquefrancaise.org/10.1051/cmlf08147},
	doi = {10.1051/cmlf08147},
	eventtitle = {Congrès Mondial de Linguistique Française 2008},
	pages = {122},
	booktitle = {Congrès Mondial de Linguistique Française 2008},
	publisher = {{EDP} Sciences},
	author = {Gérard, C.},
	urldate = {2023-08-17},
	date = {2008},
	langid = {french},
	keywords = {{HN}},
	file = {Gérard - 2008 - Genre et variations stylistiques en sémantique tex.pdf:/home/lf/Zotero/storage/4QGZE2GA/Gérard - 2008 - Genre et variations stylistiques en sémantique tex.pdf:application/pdf},
}

@incollection{carbonell_text_1998,
	location = {Berlin, Heidelberg},
	title = {Text categorization with Support Vector Machines: Learning with many relevant features},
	volume = {1398},
	url = {http://link.springer.com/10.1007/BFb0026683},
	shorttitle = {Text categorization with Support Vector Machines},
	abstract = {This paper explores the use of Support Vector Machines ({SVMs}) for learning text classi ers from examples. It analyzes the particular properties of learning with text data and identi es why {SVMs} are appropriate for this task. Empirical results support the theoretical ndings. {SVMs} achieve substantial improvements over the currently best performing methods and behave robustly over a variety of di erent learning tasks. Furthermore, they are fully automatic, eliminating the need for manual parameter tuning.},
	pages = {137--142},
	booktitle = {Machine Learning: {ECML}-98},
	publisher = {Springer Berlin Heidelberg},
	author = {Joachims, Thorsten},
	editor = {Nédellec, Claire and Rouveirol, Céline},
	editorb = {Carbonell, Jaime G. and Siekmann, Jörg and Goos, G. and Hartmanis, J. and Van Leeuwen, J.},
	editorbtype = {redactor},
	urldate = {2023-08-17},
	date = {1998},
	langid = {english},
	doi = {10.1007/BFb0026683},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {{HN}},
	file = {Joachims - 1998 - Text categorization with Support Vector Machines .pdf:/home/lf/Zotero/storage/6933BXJK/Joachims - 1998 - Text categorization with Support Vector Machines .pdf:application/pdf},
}

@thesis{silvestre_de_sacy_les_2020,
	location = {Paris, France},
	title = {Les écritures de Louis-Ferdinand Céline : Étude stylométrique et stylistique, mémoire de master 2 « Humanités numériques et computationnelles », dir. {CAMPS}, Jean-Baptiste, {PAILLET}, Anne-Marie},
	abstract = {L’étude se propose d’analyser l’évolution du style de Louis-Ferdinand Céline à travers différentes problématiques et focales. En pratiquant des analyses textométriques à grande échelle, on peut voir qu’une différence claire apparaît entre le genre pamphlétaire et romanesque. Or, si la question se pose, c’est que le statut esthétique des pamphlets pose problème ; en effet, au-delà du contenu antisémite des pamphlets, c’est toujours à « du Céline » que nous semblons avoir affaire au point de vue stylistique. Il s’agit dès lors de se demander si la saturation antisémite et le déplacement générique a une influence sur la stylistique célinienne. Si à différents genres correspond une écriture et un style différent, c’est la valeur esthétique des pamphlets qui doit être interrogée. Est-ce qu’une telle différence peut-être quantifiée ? C’est un des sujets de cette étude. Mais, une fois cette différence établie, la question se pose de savoir si des phénomènes de contamination peuvent apparaître et si l’écriture romanesque ou pamphlétaire ne surgit pas d’un genre à un autre de façon ponctuelle. Les algorithmes d’apprentissage supervisé développés pour l’analyse des textes peuvent nous permettre de répondre à ces questions. Enfin, cette interrogation sur l’évolution du style de Céline nous invite à nous intéresser sur le fait essentiel de cette évolution : la segmentation du discours par un usage particulier de la ponctuation suspensive produisant des effets multiples au niveau syntaxique, sémantique et énonciatif. En variant les focales - lecture distante, proche et méthode mixte -, ce mémoire se propose d’analyser ces questions en croisant les outils développés par les humanités numériques et les méthodes stylistiques traditionnelles d’analyse du texte.},
	pagetotal = {155},
	institution = {Université Paris, Sciences \& Lettres},
	type = {phdthesis},
	author = {Silvestre de Sacy, Antoine},
	date = {2020},
	langid = {french},
	keywords = {{HN}},
	file = {Memoire_antoine_de_sacy.pdf:/home/lf/Zotero/storage/3G7QW6NM/Memoire_antoine_de_sacy.pdf:application/pdf},
}

@online{malrieu_traitement_nodate,
	title = {Traitement Automatique des Langues : Article pp.547-577 du Vol.42 n°2 (2001) - Genres et variations morphosyntaxiques},
	url = {https://tal.revuesonline.com/article.jsp?articleId=32},
	abstract = {A partir dun corpus de 2 500 textes complets classés par genres et discours et étiqueté par 251 types détiquettes, morphosyntaxiques pour la plupart, on cherche à retrouver et valider les différents niveaux de la classification, en utilisant des pourcentages calculés sur les étiquettes. On utilise pour cela successivement des analyses univariées, pour qualifier les variations selon les catégories détiquettes, et une analyse multivariée utilisant des méthodes de classification automatique. Les résultats, à affiner, mais cependant probants, pourraient conduire à reconsidérer certains postulats admis en linguistique.},
	author = {{MALRIEU}, Denise and {RASTIER}, François},
	urldate = {2023-08-18},
	langid = {french},
	file = {Traitement Automatique des Langues \: Article pp.547-577 du Vol.42 n°2 (2001):/home/lf/Zotero/storage/88BEVHPH/article.html:text/html},
}

@online{beauvisage_traitement_nodate,
	title = {Traitement Automatique des Langues : Article pp.579-608 du Vol.42 n°2 (2001) - Morphosyntaxe et genres textuels / Exploiter des données morphosyntaxiques pour l'étude statistique des genres textuels : application au roman policier},
	url = {https://tal.revuesonline.com/article.jsp?articleId=34},
	abstract = {Ce travail évalue, à travers l'étude du genre du roman policier, variables morphosyntaxiques. Il montre qu'une telle caractérisation n'est possible qu'à travers une démarche à la fois contrastive et contextuelle, au sein de laquelle se trouvent mobilisés les situations discursives, la dimension diachronique ainsi que les modèles et les lignées génériques. Cette étude témoigne d'une conception de l'expérimentation en linguistique de corpus qui aborde avant tout le texte en situation.},
	author = {{BEAUVISAGE}, Thomas},
	urldate = {2023-08-18},
	langid = {french},
	keywords = {{HN}, morphosyntaxe},
	file = {Traitement Automatique des Langues \: Article pp.579-608 du Vol.42 n°2 (2001):/home/lf/Zotero/storage/XU2HZZQE/article.html:text/html},
}

@online{illouz_traitement_nodate,
	title = {Traitement Automatique des Langues : Article pp.501-516 du Vol.42 n°2 (2001) - Analyse statistique et géométrique de corpus textuels},
	url = {https://tal.revuesonline.com/article.jsp?articleId=30},
	abstract = {De grandes bases de données écrites permettent de représenter statistiquement des textes ou des documents en leur associant des vecteurs dans un espace à n dimensions. Le nombre de variables n correspond au nombre de traits ou primitives choisis pour décrire les documents, n est généralement très grand de sorte quune représentation planaire nest pas directement possible. Nous proposons dans cet article un nouvel espace de projection qui représente dans un seul plan toutes les données, contrairement à lAnalyse en Composantes Principales, et avec une repésentation explicite des axes, contrairement à la projection de Sammon. Une partition optimale en trois classes des variables initiales permet de définir lespace de projection comme un triangle équilatéral dont les sommets sont les barycentres de ces trois classes. Cette partition est obtenue par un algorithme de classification de type nuées dynamiques. La projection des textes dans ce triangle forme un nuage de points qui permet de visualiser leur répartition et de vérifier la pertinence des traits ou primitives choisis. Nous avons testé cette approche sur un ensemble de textes américains (Brown Corpus) en utilisant trois ensembles de traits : les caractères, les mots et les étiquettes grammaticales fournies avec le corpus.},
	author = {{ILLOUZ}, Gabriel and {JARDINO}, Michèle},
	urldate = {2023-08-18},
	langid = {french},
	file = {Traitement Automatique des Langues \: Article pp.501-516 du Vol.42 n°2 (2001):/home/lf/Zotero/storage/LYD44ILI/article.html:text/html},
}

@online{rastier_malrieu_nodate,
	title = {Malrieu \& Rastier : Genres et variations morphosyntaxiques},
	url = {http://www.revue-texto.net/Inedits/Malrieu_Rastier/Malrieu-Rastier_Genres.html},
	abstract = {A partir d’un corpus de 2. 500 textes complets classés par genres et discours et étiqueté par 251 types d’étiquettes, morphosyntaxiques pour la plupart, on cherche à retrouver et valider les différents niveaux de la classification, en utilisant des pourcentages calculés sur les étiquettes. On utilise pour cela successivement des analyses univariées, pour qualifier les variations selon les catégories d’étiquettes, et une analyse multivariée utilisant des méthodes de classification automatique. Les résultats, à affiner, mais cependant probants, pourraient conduire à reconsidérer certains postulats admis en linguistique.},
	titleaddon = {Texto !},
	author = {{RASTIER}, François and {MALRIEU}, Denise},
	urldate = {2023-08-18},
	keywords = {{HN}},
	file = {Malrieu & Rastier \: Genres et variations morphosyntaxiques:/home/lf/Zotero/storage/8XGJ38IA/Malrieu-Rastier_Genres.html:text/html},
}

@incollection{passard_rhetoriques_2010,
	location = {Louvain-la-Neuve},
	title = {Rhétoriques du pamphlet politique chez Henri Rochefort et Édouard Drumont},
	isbn = {978-2-8011-1636-4},
	url = {https://www.cairn.info/polemique-et-rhetorique--9782801116364-p-323.htm},
	series = {Champs linguistiques},
	abstract = {Qu’on tente de l’évacuer, de la dissimuler derrière une évidence fictive ou, au contraire, qu’on la mette en scène ostensiblement à des fins stratégiques, la polémique est au cœur de toute entreprise oratoire. Elle prescrit ses règles et ses armes, impose ses conditions, son terrain d’action ou de réaction : un mot de trop, un tour mal pesé, et tout le projet rhétorique se trouve mis en échec faute d’une entente pérenne sur les enjeux et les fins du combat. Horizon possible, éventualité, ressource circonstancielle, la polémique reste disponible à la croisée des genres pour coordonner et ritualiser l’échange des coups autant que le degré de leur violence.

Négliger sa pertinence, son importance topique n’a jamais pour effet que de masquer ou de récuser le principe selon lequel à l’origine et aux fondements de tout discours résident une cause à gagner, un contradicteur à évincer, des arguments à contester et, en fin de compte, un auditeur à persuader de la supériorité d’une vision du monde inscrite dans une hiérarchie des valeurs et des préférences. Provocation, incitation à la réponse, une telle parole invite à la surenchère, à la contre-attaque, à la pointe, à la recherche de l’argument imparable – cette munition discursive – qui viendrait enfermer dans ses formes la bataille des mots, et clore le rapport de force entre des protagonistes plus ou moins bien qualifiés pour soutenir cette situation incertaine sans vaciller.},
	pages = {323--337},
	booktitle = {Polémique et rhétorique},
	publisher = {De Boeck Supérieur},
	author = {Passard, Cédric},
	urldate = {2023-08-18},
	date = {2010},
	langid = {french},
	doi = {10.3917/dbu.albert.2010.01.0323},
	file = {Snapshot:/home/lf/Zotero/storage/SIU6VI4M/polemique-et-rhetorique--9782801116364-page-323.html:text/html},
}

@article{mekki_caracterisation_2020,
	title = {Caractérisation de registres de langue par extraction de motifs séquentiels émergents},
	volume = {{JADT} 2020 : 15es Journées internationales d’Analyse statistique des Données Textuelles},
	abstract = {Les registres de langue sont un trait saillant et très visible de la communication orale et écrite. Nous proposons dans cet article une méthodologie qui permet de caractériser automatiquement les registres de langues. Elle s’appuie sur un outil statistique particulier qui repose sur l’utilisation de motifs dits "séquentiels émergents". Les travaux que nous exposons ici présentent deux étapes : une première étape qui vérifie la pertinence de l’outil statistique choisi à partir de textes artificiels ; une seconde étape qui applique cet outil à des données textuelles réelles. Les résultats expérimentaux à partir de données réelles sont encourageants étant donnée la qualité des motifs caractéristiques des registres de langue retournés.},
	pages = {12},
	journaltitle = {{HAL}},
	author = {Mekki, Jade and Béchet, Nicolas and Battistelli, Delphine and Lecorvé, Gwénolé},
	date = {2020},
	langid = {french},
	keywords = {{HN}, motifs},
	file = {2020_JADT_MEKKI.pdf:/home/lf/Zotero/storage/8A5WQ6B6/2020_JADT_MEKKI.pdf:application/pdf},
}

@software{noauthor_tlfi_nodate,
	title = {{TLFi} : Trésor de la langue Française informatisé},
	url = {http://atilf.atilf.fr/tlf.htm},
	publisher = {{ATILF} - {CNRS} \& Université de Lorraine.},
	urldate = {2023-08-24},
	keywords = {{HN}},
	file = {TLFi:/home/lf/Zotero/storage/QLW86AZF/tlf.html:text/html},
}

@software{anrchapitres_anrchapitres2000romans19e20e_2022,
	title = {{ANRChapitres}/2000romans19e20e: Corpus Chapitres},
	rights = {Open Access},
	url = {https://zenodo.org/record/7446728},
	shorttitle = {{ANRChapitres}/2000romans19e20e},
	abstract = {Ceci est une version non exhaustivement corrigée du corpus de romans libres de droits en français et en .xml, rassemblé par l'{ANR} Chapitres. Il peut subsister des erreurs dans les métadonnées et la structuration des textes. Ce travail collectif n'aurait pas vu voir le jour sans @{OdysseusPolymetis}, @{CamilleKoskas}, @Malichot, @jeremynaim, @crazyjeannot, @{LeaHeid}, @glorieux-f: je les remercie mille fois pour leur aide. Pour joindre @{ANRChapitres}, écrivez à aude.leblond@sorbonne-nouvelle.fr},
	version = {v1.0.0},
	publisher = {Zenodo},
	author = {{ANRChapitres}},
	urldate = {2023-08-26},
	date = {2022-12-16},
	doi = {10.5281/ZENODO.7446728},
	keywords = {{HN}},
}

@software{anrchapitres_anrchapitres2000romans19e20e_2023,
	title = {{ANRChapitres}/2000romans19e20e},
	rights = {{CC}0-1.0},
	url = {https://github.com/ANRChapitres/2000romans19e20e},
	abstract = {Corpus de 2000 romans français du 19e et 20e siècles libres de droit en xml-tei},
	author = {{ANRChapitres}},
	urldate = {2023-08-26},
	date = {2023-01-17},
	note = {original-date: 2022-11-15T10:41:23Z},
	keywords = {{HN}},
}

@online{noauthor_machine_2023,
	title = {Machine à vecteurs de support},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://fr.wikipedia.org/w/index.php?title=Machine_%C3%A0_vecteurs_de_support&oldid=206160456},
	abstract = {Les machines à vecteurs de support ou séparateurs à vaste marge (en anglais support-vector machine, {SVM}) sont un ensemble de techniques d'apprentissage supervisé destinées à résoudre des problèmes de discrimination et de régression. Les {SVM} sont une généralisation des classifieurs linéaires.
Les séparateurs à vaste marge ont été développés dans les années 1990 à partir des considérations théoriques de Vladimir Vapnik sur le développement d'une théorie statistique de l'apprentissage : la théorie de Vapnik-Tchervonenkis. Ils ont rapidement été adoptés pour leur capacité à travailler avec des données de grandes dimensions, le faible nombre d'hyperparamètres, leurs garanties théoriques, et leurs bons résultats en pratique.
Les {SVM} ont été appliqués à de très nombreux domaines (bio-informatique, recherche d'information, vision par ordinateur, finance…). Selon les données, la performance des machines à vecteurs de support est de même ordre, ou même supérieure, à celle d'un réseau de neurones ou d'un modèle de mélanges gaussiens[réf. souhaitée].},
	booktitle = {Wikipédia},
	urldate = {2023-09-10},
	date = {2023-07-19},
	langid = {french},
	note = {Page Version {ID}: 206160456},
	keywords = {{HN}},
	file = {Snapshot:/home/lf/Zotero/storage/MPYJ2A9X/Machine_à_vecteurs_de_support.html:text/html},
}
